# quickstart_agent.py
"""
å¿«é€Ÿå…¥é—¨ - éº»å°†AI Agent
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨PPOè®­ç»ƒå’Œè¯„ä¼°éº»å°†AI
"""

import sys
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def demo_training():
    """æ¼”ç¤ºè®­ç»ƒæµç¨‹ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼Œç”¨äºæµ‹è¯•ï¼‰"""
    print("=" * 80)
    print(" " * 25 + "éº»å°†AIè®­ç»ƒå¿«é€Ÿæ¼”ç¤º")
    print("=" * 80 + "\n")

    from mahjong_agent import MahjongTrainer, get_fast_config

    # ä½¿ç”¨å¿«é€Ÿé…ç½®ï¼ˆé€‚åˆæµ‹è¯•ï¼‰
    config = get_fast_config()

    # è°ƒæ•´å‚æ•°ä»¥ä¾¿å¿«é€Ÿæ¼”ç¤º
    config.rollout_steps = 256  # å‡å°‘rolloutæ­¥æ•°
    config.total_timesteps = 10000  # åªè®­ç»ƒ10kæ­¥ï¼ˆæ¼”ç¤ºç”¨ï¼‰
    config.log_interval = 2  # æ›´é¢‘ç¹åœ°è®°å½•æ—¥å¿—
    config.save_interval = 5  # æ›´é¢‘ç¹åœ°ä¿å­˜
    config.verbose = True

    print("é…ç½®ä¿¡æ¯:")
    print(f"  è®¾å¤‡: {config.device}")
    print(f"  æ€»æ­¥æ•°: {config.total_timesteps:,}")
    print(f"  Rolloutæ­¥æ•°: {config.rollout_steps}")
    print(f"  å­¦ä¹ ç‡: {config.learning_rate}")
    print(f"  éšè—å±‚ç»´åº¦: {config.hidden_dim}")
    print()

    # åˆ›å»ºè®­ç»ƒå™¨
    print("åˆå§‹åŒ–è®­ç»ƒå™¨...")
    trainer = MahjongTrainer(config=config)

    print("\nå¼€å§‹è®­ç»ƒ...\n")

    # å¼€å§‹è®­ç»ƒ
    try:
        trainer.train()
        print("\nâœ“ è®­ç»ƒå®Œæˆï¼")
        print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {config.save_dir}")
    except KeyboardInterrupt:
        print("\nè®­ç»ƒè¢«ä¸­æ–­")
        print("ä¿å­˜å½“å‰æ¨¡å‹...")
        trainer.save_checkpoint("interrupted.pt")
        print("âœ“ æ¨¡å‹å·²ä¿å­˜")


def demo_model_architecture():
    """æ¼”ç¤ºæ¨¡å‹æ¶æ„"""
    print("=" * 80)
    print(" " * 25 + "éº»å°†AIæ¨¡å‹æ¶æ„å±•ç¤º")
    print("=" * 80 + "\n")

    import torch
    from mahjong_agent import MahjongActorCritic, get_default_config

    config = get_default_config()

    # åˆ›å»ºæ¨¡å‹
    model = MahjongActorCritic(config)

    print("æ¨¡å‹ç»“æ„:")
    print("-" * 80)
    print(model)
    print("-" * 80)

    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"\nå‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (float32)")

    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\næµ‹è¯•å‰å‘ä¼ æ’­...")

    # åˆ›å»ºå‡æ•°æ®
    batch_size = 4
    obs = {
        "hand": torch.zeros(batch_size, 34),
        "drawn_tile": torch.zeros(batch_size, 34),
        "rivers": torch.zeros(batch_size, 4, 34),
        "melds": torch.zeros(batch_size, 4, 34),
        "riichi_status": torch.zeros(batch_size, 4),
        "scores": torch.zeros(batch_size, 4),
        "dora_indicators": torch.zeros(batch_size, 5, 34),
        "game_info": torch.zeros(batch_size, 5),
        "phase_info": torch.zeros(batch_size, 3),
    }
    action_mask = torch.ones(batch_size, 112)

    with torch.no_grad():
        action, log_prob, entropy, value = model.get_action_and_value(
            obs, action_mask=action_mask
        )

    print(f"  è¾“å…¥æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"  è¾“å‡ºåŠ¨ä½œå½¢çŠ¶: {action.shape}")
    print(f"  ä»·å€¼ä¼°è®¡å½¢çŠ¶: {value.shape}")
    print(f"  ç¤ºä¾‹ä»·å€¼: {value[0].item():.3f}")
    print("\nâœ“ æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")


def demo_environment_interaction():
    """æ¼”ç¤ºä¸ç¯å¢ƒçš„äº¤äº’"""
    print("=" * 80)
    print(" " * 25 + "AIä¸ç¯å¢ƒäº¤äº’æ¼”ç¤º")
    print("=" * 80 + "\n")

    import torch
    import numpy as np
    from mahjong_environment import MahjongEnv
    from mahjong_agent import MahjongActorCritic, get_default_config

    # åˆ›å»ºç¯å¢ƒå’Œæ¨¡å‹
    env = MahjongEnv(render_mode="human", seed=42)
    config = get_default_config()
    model = MahjongActorCritic(config)
    model.eval()

    device = torch.device("cpu")
    model = model.to(device)

    print("ç¯å¢ƒå’Œæ¨¡å‹å·²åˆ›å»º\n")

    # é‡ç½®ç¯å¢ƒ
    obs, info = env.reset(seed=42)
    print("ç¯å¢ƒå·²é‡ç½®")
    print(f"å½“å‰ç©å®¶: {env.agent_selection}\n")

    # æ‰§è¡Œå‡ æ­¥
    steps = 10
    print(f"æ‰§è¡Œ {steps} æ­¥...")

    for step in range(steps):
        if env.agent_selection is None:
            print("æ¸¸æˆç»“æŸ")
            break

        current_agent = env.agent_selection
        action_mask = obs["action_mask"]

        # å‡†å¤‡è§‚æµ‹
        torch_obs = {}
        for key, value in obs.items():
            if key != "action_mask":
                torch_obs[key] = torch.from_numpy(value).unsqueeze(0).to(device)

        torch_action_mask = torch.from_numpy(action_mask).unsqueeze(0).to(device)

        # é€‰æ‹©åŠ¨ä½œ
        with torch.no_grad():
            action, log_prob, entropy, value = model.get_action_and_value(
                torch_obs, action_mask=torch_action_mask
            )

        action_np = action.cpu().item()

        # è§£ç åŠ¨ä½œ
        from mahjong_environment.utils.action_encoder import ActionEncoder

        action_type, params = ActionEncoder.decode_action(action_np)

        print(f"\næ­¥éª¤ {step + 1}: {current_agent}")
        print(f"  åŠ¨ä½œ: {action_type} {params}")
        print(f"  ä»·å€¼: {value.cpu().item():.3f}")

        # æ‰§è¡ŒåŠ¨ä½œ
        env.step(action_np)

        # è·å–ä¸‹ä¸€ä¸ªè§‚æµ‹
        if env.agent_selection is not None:
            obs = env.observe(env.agent_selection)

    print("\n" + "=" * 80)
    env.render()
    print("\nâœ“ äº¤äº’æ¼”ç¤ºå®Œæˆï¼")


def show_menu():
    """æ˜¾ç¤ºèœå•"""
    print("\n" + "=" * 80)
    print(" " * 20 + "éº»å°†AI Agent å¿«é€Ÿå…¥é—¨èœå•")
    print("=" * 80)
    print("\nè¯·é€‰æ‹©è¦æ‰§è¡Œçš„æ¼”ç¤º:")
    print("  1. æ¨¡å‹æ¶æ„å±•ç¤º")
    print("  2. ç¯å¢ƒäº¤äº’æ¼”ç¤º")
    print("  3. è®­ç»ƒæ¼”ç¤ºï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰")
    print("  0. é€€å‡º")
    print()


def main():
    """ä¸»å‡½æ•°"""
    import sys

    print("\nğŸ€„ æ¬¢è¿ä½¿ç”¨éº»å°†AI Agentç³»ç»Ÿï¼\n")

    while True:
        show_menu()

        try:
            choice = input("è¯·è¾“å…¥é€‰é¡¹ (0-3): ").strip()

            if choice == "0":
                print("\nå†è§ï¼")
                break
            elif choice == "1":
                demo_model_architecture()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            elif choice == "2":
                demo_environment_interaction()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            elif choice == "3":
                confirm = (
                    input("\nè®­ç»ƒå°†éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œç¡®å®šç»§ç»­? (y/n): ").strip().lower()
                )
                if confirm == "y":
                    demo_training()
                    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
                else:
                    print("å·²å–æ¶ˆ")
            else:
                print("æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©")
        except KeyboardInterrupt:
            print("\n\næ“ä½œå·²å–æ¶ˆ")
            break
        except Exception as e:
            print(f"\né”™è¯¯: {e}")
            import traceback

            traceback.print_exc()
            input("\næŒ‰å›è½¦é”®ç»§ç»­...")


if __name__ == "__main__":
    main()
