# éº»å°†AI Agent å®Œæ•´ä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨åŸºäºPPOç®—æ³•çš„éº»å°†AIç³»ç»Ÿã€‚

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [è¯¦ç»†æ•™ç¨‹](#è¯¦ç»†æ•™ç¨‹)
3. [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
4. [è®­ç»ƒæŠ€å·§](#è®­ç»ƒæŠ€å·§)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨å¿«é€Ÿå…¥é—¨è„šæœ¬

æœ€ç®€å•çš„æ–¹å¼æ˜¯ä½¿ç”¨äº¤äº’å¼å¿«é€Ÿå…¥é—¨è„šæœ¬ï¼š

```bash
python quickstart_agent.py
```

è¿™å°†æ˜¾ç¤ºä¸€ä¸ªèœå•ï¼ŒåŒ…å«ä»¥ä¸‹é€‰é¡¹ï¼š
- æ¨¡å‹æ¶æ„å±•ç¤º
- ç¯å¢ƒäº¤äº’æ¼”ç¤º
- è®­ç»ƒæ¼”ç¤ºï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰

### æ–¹æ³•äºŒï¼šç›´æ¥è®­ç»ƒ

#### Windows:
```bash
train_quickstart.bat
```

#### Linux/Mac:
```bash
chmod +x train_quickstart.sh
./train_quickstart.sh
```

#### æ‰‹åŠ¨æ‰§è¡Œ:
```bash
# å®‰è£…ä¾èµ–
pip install -r mahjong_agent/requirements.txt

# å¼€å§‹è®­ç»ƒ
python -m mahjong_agent.train --config fast --device cuda
```

---

## ğŸ“š è¯¦ç»†æ•™ç¨‹

### 1. ç¯å¢ƒå‡†å¤‡

#### å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ç¯å¢ƒä¾èµ–
pip install -r mahjong_environment/requirements.txt

# Agentä¾èµ–
pip install -r mahjong_agent/requirements.txt
```

#### éªŒè¯å®‰è£…

```python
# æµ‹è¯•ç¯å¢ƒ
from mahjong_environment import MahjongEnv
env = MahjongEnv()
obs, info = env.reset()
print("âœ“ ç¯å¢ƒå®‰è£…æˆåŠŸ")

# æµ‹è¯•Agent
from mahjong_agent import MahjongActorCritic, get_default_config
model = MahjongActorCritic(get_default_config())
print("âœ“ Agentå®‰è£…æˆåŠŸ")
```

### 2. åŸºç¡€è®­ç»ƒ

#### ä½¿ç”¨é¢„è®¾é…ç½®

```python
from mahjong_agent import MahjongTrainer, get_default_config

# è·å–é»˜è®¤é…ç½®
config = get_default_config()

# åˆ›å»ºè®­ç»ƒå™¨
trainer = MahjongTrainer(config=config)

# å¼€å§‹è®­ç»ƒ
trainer.train()
```

#### è‡ªå®šä¹‰é…ç½®

```python
from mahjong_agent import MahjongTrainer, PPOConfig

# åˆ›å»ºè‡ªå®šä¹‰é…ç½®
config = PPOConfig()
config.learning_rate = 1e-4
config.total_timesteps = 5_000_000
config.hidden_dim = 1024
config.use_transformer = True

# è®­ç»ƒ
trainer = MahjongTrainer(config=config)
trainer.train()
```

### 3. ç›‘æ§è®­ç»ƒ

#### ä½¿ç”¨TensorBoard

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir logs/

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
# http://localhost:6006
```

#### ä¸»è¦ç›‘æ§æŒ‡æ ‡

- **train/mean_episode_reward**: å¹³å‡å›æŠ¥ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
- **train/policy_loss**: ç­–ç•¥æŸå¤±
- **train/value_loss**: ä»·å€¼æŸå¤±
- **train/entropy**: ç­–ç•¥ç†µï¼ˆæ¢ç´¢ç¨‹åº¦ï¼‰
- **train/clip_fraction**: PPOè£å‰ªæ¯”ä¾‹
- **eval/win_rate**: è¯„ä¼°èƒœç‡

### 4. æ¢å¤è®­ç»ƒ

å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œå¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼š

```bash
python -m mahjong_agent.train --checkpoint checkpoints/checkpoint_100.pt
```

æˆ–åœ¨ä»£ç ä¸­ï¼š

```python
trainer = MahjongTrainer(checkpoint_path="checkpoints/checkpoint_100.pt")
trainer.train()
```

### 5. è¯„ä¼°æ¨¡å‹

#### å‘½ä»¤è¡Œè¯„ä¼°

```bash
# æ ‡å‡†è¯„ä¼°ï¼ˆ100å±€ï¼‰
python -m mahjong_agent.evaluate --model checkpoints/final_model.pt --episodes 100

# äº¤äº’å¼æ¼”ç¤º
python -m mahjong_agent.evaluate --model checkpoints/final_model.pt --interactive

# è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„
python -m mahjong_agent.evaluate --model checkpoints/final_model.pt --output my_report.txt
```

#### ä»£ç è¯„ä¼°

```python
from mahjong_agent import MahjongEvaluator

# åˆ›å»ºè¯„ä¼°å™¨
evaluator = MahjongEvaluator(
    model_path="checkpoints/final_model.pt",
    device="cuda"
)

# è¯„ä¼°æ€§èƒ½
results = evaluator.evaluate(num_episodes=100)
print(f"èƒœç‡: {results['player_0_win_rate']:.2%}")
print(f"å¹³å‡åˆ†æ•°: {results['player_0_mean_score']:.1f}")

# ä¿å­˜æŠ¥å‘Š
evaluator.save_evaluation_report(results, "report.txt")
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### é¢„è®¾é…ç½®å¯¹æ¯”

| é…ç½® | è®­ç»ƒæ—¶é—´ | æ¨¡å‹å¤§å° | æ¨èåœºæ™¯ |
|------|---------|---------|---------|
| **fast** | çŸ­ (~2å°æ—¶) | å° (~50MB) | å¿«é€Ÿæµ‹è¯•ã€è°ƒè¯• |
| **default** | ä¸­ (~10å°æ—¶) | ä¸­ (~200MB) | æ—¥å¸¸è®­ç»ƒ |
| **high_performance** | é•¿ (~50å°æ—¶) | å¤§ (~500MB) | è¿½æ±‚æœ€ä½³æ€§èƒ½ |

### å…³é”®è¶…å‚æ•°è¯¦è§£

#### å­¦ä¹ ç‡ç›¸å…³

```python
config.learning_rate = 3e-4  # åˆå§‹å­¦ä¹ ç‡
config.lr_schedule = "linear"  # å­¦ä¹ ç‡è°ƒåº¦: constant/linear/cosine
```

- å­¦ä¹ ç‡å¤ªå¤§ï¼šè®­ç»ƒä¸ç¨³å®šï¼ŒæŸå¤±éœ‡è¡
- å­¦ä¹ ç‡å¤ªå°ï¼šè®­ç»ƒç¼“æ…¢ï¼Œå¯èƒ½ä¸æ”¶æ•›
- æ¨èèŒƒå›´ï¼š1e-4 åˆ° 5e-4

#### PPOæ ¸å¿ƒå‚æ•°

```python
config.gamma = 0.99          # æŠ˜æ‰£å› å­ï¼ˆ0.95-0.995ï¼‰
config.gae_lambda = 0.95     # GAE lambdaï¼ˆ0.9-0.99ï¼‰
config.clip_range = 0.2      # PPOè£å‰ªèŒƒå›´ï¼ˆ0.1-0.3ï¼‰
```

- **gamma**: è¶Šå¤§è¶Šé‡è§†é•¿æœŸå¥–åŠ±ï¼Œè¶Šå°è¶Šé‡è§†çŸ­æœŸå¥–åŠ±
- **gae_lambda**: å¹³è¡¡åå·®å’Œæ–¹å·®ï¼Œ0.95æ˜¯å¸¸ç”¨å€¼
- **clip_range**: é™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ï¼Œé˜²æ­¢æ›´æ–°è¿‡å¤§

#### ç½‘ç»œæ¶æ„

```python
config.hidden_dim = 512              # éšè—å±‚ç»´åº¦
config.num_hidden_layers = 3         # å±‚æ•°
config.use_transformer = False       # æ˜¯å¦ä½¿ç”¨Transformer
config.num_transformer_layers = 2    # Transformerå±‚æ•°
```

- **hidden_dim**: è¶Šå¤§æ¨¡å‹å®¹é‡è¶Šå¤§ï¼Œä½†è®­ç»ƒè¶Šæ…¢
- **num_hidden_layers**: 3-4å±‚é€šå¸¸è¶³å¤Ÿ
- **Transformer**: å¯ä»¥æ•æ‰æ›´å¤æ‚çš„å…³ç³»ï¼Œä½†è®¡ç®—æ˜‚è´µ

#### è®­ç»ƒæµç¨‹

```python
config.rollout_steps = 2048      # æ¯æ¬¡æ”¶é›†çš„æ­¥æ•°
config.mini_batch_size = 256     # æ‰¹æ¬¡å¤§å°
config.num_epochs = 4            # æ¯æ¬¡æ›´æ–°çš„epochæ•°
```

- **rollout_steps**: è¶Šå¤§è¶Šç¨³å®šï¼Œä½†æ›´æ–°é¢‘ç‡è¶Šä½
- **mini_batch_size**: æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼Œé€šå¸¸128-512
- **num_epochs**: 4-8é€šå¸¸è¶³å¤Ÿ

---

## ğŸ’¡ è®­ç»ƒæŠ€å·§

### 1. åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥

#### æ¢ç´¢é˜¶æ®µï¼ˆ0-1Mæ­¥ï¼‰
- ç›®æ ‡ï¼šè®©AIæ¢ç´¢å„ç§ç­–ç•¥
- é…ç½®ï¼š
  ```python
  config.entropy_coef = 0.02  # è¾ƒé«˜çš„ç†µç³»æ•°
  config.learning_rate = 3e-4
  ```

#### ä¼˜åŒ–é˜¶æ®µï¼ˆ1M-5Mæ­¥ï¼‰
- ç›®æ ‡ï¼šä¼˜åŒ–ç­–ç•¥ï¼Œæé«˜èƒœç‡
- é…ç½®ï¼š
  ```python
  config.entropy_coef = 0.01  # æ ‡å‡†ç†µç³»æ•°
  config.learning_rate = 2e-4
  ```

#### ç²¾ç‚¼é˜¶æ®µï¼ˆ5M+æ­¥ï¼‰
- ç›®æ ‡ï¼šå¾®è°ƒç»†èŠ‚ï¼Œè¿½æ±‚æœ€ä½³æ€§èƒ½
- é…ç½®ï¼š
  ```python
  config.entropy_coef = 0.005  # é™ä½ç†µç³»æ•°
  config.learning_rate = 1e-4  # é™ä½å­¦ä¹ ç‡
  ```

### 2. è¶…å‚æ•°è°ƒä¼˜å»ºè®®

| é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|---------|---------|
| è®­ç»ƒä¸æ”¶æ•› | å­¦ä¹ ç‡å¤ªå¤§ | é™ä½learning_rate |
| æ”¶æ•›å¤ªæ…¢ | å­¦ä¹ ç‡å¤ªå° | æé«˜learning_rate |
| æŸå¤±éœ‡è¡ | æ‰¹æ¬¡å¤ªå°æˆ–å­¦ä¹ ç‡å¤ªå¤§ | å¢åŠ mini_batch_sizeæˆ–é™ä½learning_rate |
| è¿‡æ‹Ÿåˆ | æ¢ç´¢ä¸è¶³ | å¢åŠ entropy_coef |
| æ¬ æ‹Ÿåˆ | æ¨¡å‹å®¹é‡ä¸è¶³ | å¢åŠ hidden_dimæˆ–num_hidden_layers |

### 3. æ€§èƒ½ä¼˜åŒ–

#### GPUä¼˜åŒ–

```python
# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå¦‚æœGPUæ”¯æŒï¼‰
config.device = "cuda"

# å¢åŠ æ‰¹æ¬¡å¤§å°
config.mini_batch_size = 512

# ä½¿ç”¨æ›´å¤§çš„rollout
config.rollout_steps = 4096
```

#### CPUè®­ç»ƒ

```python
# è®¾ç½®è®¾å¤‡ä¸ºCPU
config.device = "cpu"

# è°ƒæ•´çº¿ç¨‹æ•°
config.num_threads = 8

# å‡å°æ‰¹æ¬¡å¤§å°
config.mini_batch_size = 128
config.rollout_steps = 1024
```

### 4. å®æˆ˜æ¡ˆä¾‹

#### æ¡ˆä¾‹1ï¼šå¿«é€ŸåŸå‹

ç›®æ ‡ï¼šå¿«é€ŸéªŒè¯æƒ³æ³•ï¼Œ2å°æ—¶å†…çœ‹åˆ°ç»“æœ

```python
from mahjong_agent import MahjongTrainer, get_fast_config

config = get_fast_config()
config.total_timesteps = 100_000
config.rollout_steps = 512

trainer = MahjongTrainer(config=config)
trainer.train()
```

#### æ¡ˆä¾‹2ï¼šæ ‡å‡†è®­ç»ƒ

ç›®æ ‡ï¼šè·å¾—ä¸é”™çš„æ€§èƒ½ï¼Œ10å°æ—¶è®­ç»ƒ

```python
from mahjong_agent import MahjongTrainer, get_default_config

config = get_default_config()
config.total_timesteps = 5_000_000

trainer = MahjongTrainer(config=config)
trainer.train()
```

#### æ¡ˆä¾‹3ï¼šè¿½æ±‚æè‡´

ç›®æ ‡ï¼šè·å¾—æœ€ä½³æ€§èƒ½ï¼Œæ•°å¤©è®­ç»ƒ

```python
from mahjong_agent import MahjongTrainer, get_high_performance_config

config = get_high_performance_config()
config.total_timesteps = 50_000_000
config.use_transformer = True

trainer = MahjongTrainer(config=config)
trainer.train()
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

**A**: å–å†³äºé…ç½®å’Œç¡¬ä»¶ï¼š
- **fasté…ç½®** + GPU: ~2å°æ—¶
- **defaulté…ç½®** + GPU: ~10å°æ—¶
- **high_performanceé…ç½®** + GPU: ~50å°æ—¶
- CPUè®­ç»ƒä¼šæ…¢5-10å€

### Q2: éœ€è¦ä»€ä¹ˆæ ·çš„ç¡¬ä»¶ï¼Ÿ

**A**: æœ€ä½è¦æ±‚ï¼š
- CPU: 4æ ¸ä»¥ä¸Š
- RAM: 8GB
- GPUï¼ˆå¯é€‰ï¼‰: 6GBæ˜¾å­˜

æ¨èé…ç½®ï¼š
- CPU: 8æ ¸ä»¥ä¸Š
- RAM: 16GB
- GPU: RTX 3060 æˆ–æ›´å¥½ï¼ˆ12GBæ˜¾å­˜ï¼‰

### Q3: å¦‚ä½•åˆ¤æ–­è®­ç»ƒæ˜¯å¦æˆåŠŸï¼Ÿ

**A**: è§‚å¯Ÿä»¥ä¸‹æŒ‡æ ‡ï¼š
1. **mean_episode_reward**: åº”è¯¥é€æ¸ä¸Šå‡
2. **eval/win_rate**: å¯¹æŠ—éšæœºç­–ç•¥åº”è¾¾åˆ°60%+
3. **entropy**: åº”è¯¥é€æ¸ä¸‹é™ï¼ˆè¡¨ç¤ºç­–ç•¥è¶Šæ¥è¶Šç¡®å®šï¼‰
4. **policy_loss**: åº”è¯¥è¶‹äºç¨³å®š

### Q4: è®­ç»ƒä¸­æ–­äº†æ€ä¹ˆåŠï¼Ÿ

**A**: ä½¿ç”¨æ£€æŸ¥ç‚¹æ¢å¤ï¼š
```bash
python -m mahjong_agent.train --checkpoint checkpoints/checkpoint_XXX.pt
```

### Q5: å¦‚ä½•è°ƒæ•´å¥–åŠ±å‡½æ•°ï¼Ÿ

**A**: åœ¨ç¯å¢ƒä»£ç ä¸­ä¿®æ”¹å¥–åŠ±è®¡ç®—é€»è¾‘ã€‚ä¸»è¦å¥–åŠ±ç‚¹ï¼š
- å’Œç‰Œï¼šæ ¹æ®ç•ªæ•°å’Œç‚¹æ•°ç»™å¥–åŠ±
- æ”¾é“³ï¼šè´Ÿå¥–åŠ±
- ç«‹ç›´ï¼šå°é¢å¥–åŠ±/æƒ©ç½šï¼ˆé¼“åŠ±/æŠ‘åˆ¶ç«‹ç›´ï¼‰
- æ¸¸æˆç»“æŸï¼šæ ¹æ®æœ€ç»ˆæ’åç»™å¥–åŠ±

### Q6: å¯ä»¥ä½¿ç”¨å¤šä¸ªGPUå—ï¼Ÿ

**A**: å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒå¤šGPUè®­ç»ƒã€‚å»ºè®®ï¼š
- ä½¿ç”¨å•ä¸ªé«˜æ€§èƒ½GPU
- æˆ–è¿è¡Œå¤šä¸ªç‹¬ç«‹è®­ç»ƒå®éªŒ

### Q7: æ¨¡å‹å¤ªå¤§æ— æ³•åŠ è½½ï¼Ÿ

**A**: å°è¯•ï¼š
```python
# ä½¿ç”¨CPUåŠ è½½
checkpoint = torch.load(path, map_location='cpu')

# æˆ–å‡å°æ¨¡å‹å¤§å°
config.hidden_dim = 256
config.num_hidden_layers = 2
```

### Q8: å¦‚ä½•ä¸äººç±»å¯¹æˆ˜ï¼Ÿ

**A**: éœ€è¦å¼€å‘äº¤äº’ç•Œé¢ã€‚å¯ä»¥å‚è€ƒevaluate.pyä¸­çš„play_interactiveæ–¹æ³•ï¼Œå¹¶æ‰©å±•ä¸ºGUIã€‚

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### å¯¹æˆ˜éšæœºç­–ç•¥

| è®­ç»ƒæ­¥æ•° | èƒœç‡ | å¹³å‡åˆ†æ•° | è£å’Œç‡ |
|---------|------|---------|-------|
| 100K | 30% | 26000 | 5% |
| 500K | 45% | 28000 | 15% |
| 1M | 60% | 30000 | 25% |
| 5M | 75% | 33000 | 35% |
| 10M | 85% | 35000 | 45% |

### è®­ç»ƒæ›²çº¿ç¤ºä¾‹

```
Episode Reward:
  0K:  -5.0
  1M:  +2.0
  5M:  +8.0
 10M: +12.0

Win Rate:
  0K:  25%
  1M:  60%
  5M:  75%
 10M:  85%
```

---

## ğŸ”— ç›¸å…³é“¾æ¥

- [PPOè®ºæ–‡](https://arxiv.org/abs/1707.06347)
- [å¼ºåŒ–å­¦ä¹ æ•™ç¨‹](https://spinningup.openai.com/)
- [PyTorchæ–‡æ¡£](https://pytorch.org/docs/)
- [TensorBoardä½¿ç”¨](https://www.tensorflow.org/tensorboard)

---

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ä¸ä¸»é¡¹ç›®ç›¸åŒçš„è®¸å¯è¯ã€‚

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿æIssueï¼** ğŸ€„
